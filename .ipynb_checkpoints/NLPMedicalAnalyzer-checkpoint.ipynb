{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/isaashka/NLPMedicalAnalyzer/blob/main/NLPMedicalAnalyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3CLxyK4kjm0"
   },
   "source": [
    "# Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 13:58:50.944 Python[34192:419801] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "mu_0NBfMatJu",
    "outputId": "a6ca6c9b-70ca-44de-df49-3853e467ba2a"
   },
   "outputs": [
    {
     "ename": "MessageError",
     "evalue": "Error: credential propagation was unsuccessful",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ef3c54079636>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# explaination of drive.mount()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# This will prompt for authorization for accessing the data on your Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/gdrive', force_remount=True)\n",
    "# # explaination of drive.mount()\n",
    "# # This will prompt for authorization for accessing the data on your Google Drive\n",
    "# # You need to (i) click the link showed after execute, (ii) copy the code,\n",
    "# # (iii) paste below and (iv) press \"Enter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model specific imports\n",
    "from decimal import Decimal\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from nltk.util import ngrams\n",
    "import math\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSDZHGxxbS4O"
   },
   "source": [
    "# Data Preprocessing\n",
    "### Goal: convert user input --> symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "symptoms_dataset = pd.read_csv(\"Dataset/dis_sym_dataset_comb.csv\")\n",
    "\n",
    "# extract features to use as a symptom array\n",
    "X = symptoms_dataset.iloc[:, 1:]\n",
    "dataset_symptoms = list(X.columns)\n",
    "# dataset_symptoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "import re\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_input():\n",
    "    print(\"Enter symptoms: \")\n",
    "    user_input = input()\n",
    "    return normalize_user_input(user_input)\n",
    "\n",
    "def correct_spelling(user_input):\n",
    "    spell = SpellChecker()\n",
    "    words = user_input.split()\n",
    "    corrected_words = [spell.correction(word) for word in words]\n",
    "    return ' '.join(corrected_words)\n",
    "\n",
    "def normalize_user_input(user_input):\n",
    "    # lowercase\n",
    "    normalized_input = user_input.lower()\n",
    "    # fix contractions\n",
    "    normalized_input = contractions.fix(normalized_input)\n",
    "    # get rid of punctuation\n",
    "    normalized_input = re.sub(r'[^\\w\\s]', '', normalized_input)\n",
    "\n",
    "    normalized_input = correct_spelling(normalized_input)\n",
    "    # print(normalized_input)\n",
    "    return(normalized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter symptoms: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  I have been having migraines and headaches. I can't sleep. My whole body is shaking and shivering. I feel dizzy sometimes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i have been having migraines and headaches i cannot sleep my whole body is shaking and shivering i feel dizzy sometimes'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_symptoms = user_input()\n",
    "user_symptoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ngram approach\n",
    "\n",
    "\n",
    "Test input: I have been having migraines and headaches. I can't sleep. My whole body is shaking and shivering. I feel dizzy sometimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_symptom_phrases(tokens, symptom_keywords, body_parts, n=2):\n",
    "    symptom_phrases = []\n",
    "    ngrams_list = list(ngrams(tokens, n))\n",
    "\n",
    "    for ngram in ngrams_list:\n",
    "        for keyword in symptom_keywords:\n",
    "            for body_part in body_parts:\n",
    "                if keyword in ngram and body_part in ngram:\n",
    "                    symptom_phrases.append(' '.join(ngram))\n",
    "\n",
    "    return symptom_phrases\n",
    "\n",
    "# Lemmatize input\n",
    "def lemmatize_tokens(tokens):\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    lemmatized_tokens = []  \n",
    "    for token in tokens:\n",
    "        lemmatized_tokens.append(lemmatizer.lemmatize(token))\n",
    "    return lemmatized_tokens\n",
    "\n",
    "def tokenize_user_symptoms():\n",
    "    print(\"Enter symptoms: \")\n",
    "    \n",
    "    symptoms = input()\n",
    "    # tokenize input\n",
    "    symptom_tokens = word_tokenize(symptoms)\n",
    "\n",
    "    # lemmatize input\n",
    "    symptom_tokens_lemmatized = lemmatize_tokens(symptom_tokens)\n",
    "\n",
    "    # find symptom phrases using n-grams\n",
    "    symptom_phrases = find_symptom_phrases(symptom_tokens_lemmatized, \\\n",
    "                                           dataset_symptoms, dataset_symptoms) # dataset_symptoms = symptoms retrieved from the dataset\n",
    "    \n",
    "    return symptom_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter symptoms: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m extracted_symptoms \u001b[38;5;241m=\u001b[39m \u001b[43mtokenize_user_symptoms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHere\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms your list of symptoms: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m, in \u001b[0;36mtokenize_user_symptoms\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_user_symptoms\u001b[39m():\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter symptoms: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m     symptoms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# tokenize input\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     symptom_tokens \u001b[38;5;241m=\u001b[39m word_tokenize(symptoms)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py:1270\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1268\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ipykernel/kernelbase.py:1313\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1311\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "extracted_symptoms = tokenize_user_symptoms()\n",
    "print()\n",
    "print('Here\\'s your list of symptoms: ')\n",
    "print(extracted_symptoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.41.2)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.23.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers pandas nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "# !pip install transformers pandas nltk\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained NER model that's specialized for biomedical text\n",
    "ner = pipeline(\"ner\", model=\"d4data/biomedical-ner-all\")\n",
    "\n",
    "# Load the symptoms dataset\n",
    "symptoms_dataset = pd.read_csv(\"Dataset/dis_sym_dataset_comb.csv\")\n",
    "\n",
    "def extract_symptoms(text):\n",
    "    # Use the NER pipeline to extract entities\n",
    "    entities = ner(text)\n",
    "    \n",
    "    # Extract symptom-related entities detected by the model\n",
    "    symptoms = [entity['word'] for entity in entities if 'symptom' in entity['entity'].lower()]\n",
    "    \n",
    "    # Tokenize the text for manual matching\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Add manually matched symptoms from the dataset\n",
    "    for token in tokens:\n",
    "        if token in dataset_symptoms and token not in symptoms:\n",
    "            symptoms.append(token)\n",
    "    \n",
    "    return symptoms\n",
    "\n",
    "# Function to clean and join tokens into keywords\n",
    "def clean_keywords(keywords):\n",
    "    clean_tokens = []\n",
    "    for token in keywords:\n",
    "        if token.startswith(\"##\"):\n",
    "            clean_tokens[-1] = clean_tokens[-1] + token[2:]\n",
    "        else:\n",
    "            clean_tokens.append(token)\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Symptoms: ['mig', '##raine', 'headache', 'cannot', 'sleep', 'shaking', 'shivering', 'dizzy', 'fever']\n",
      "Keywords: ['migraine', 'headache', 'cannot', 'sleep', 'shaking', 'shivering', 'dizzy', 'fever']\n"
     ]
    }
   ],
   "source": [
    "# Example user input\n",
    "start_user_input = \"I have been having migraines and headaches. I can't sleep. My whole body is shaking and shivering. I feel dizzy sometimes. I have a fever.\"\n",
    "new_user_input = normalize_user_input(start_user_input)\n",
    "\n",
    "# Extract symptoms\n",
    "symptoms = extract_symptoms(new_user_input)\n",
    "\n",
    "# Clean and join the tokens into keywords\n",
    "keywords = clean_keywords(symptoms)\n",
    "\n",
    "# Display the symptoms\n",
    "print(\"Extracted Symptoms:\", symptoms)\n",
    "print(\"Keywords:\", keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expand list of symptoms by finding synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/sasha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# find synonyms for extracted keywords\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.25.1)\n",
      "Requirement already satisfied: Levenshtein==0.25.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-Levenshtein) (0.25.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from Levenshtein==0.25.1->python-Levenshtein) (3.9.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get synonyms of a list of words\n",
    "def get_synonyms(words):\n",
    "    synonyms = set()\n",
    "    for word in words:\n",
    "        # Get synsets (sets of synonyms) for each word\n",
    "        synsets = wordnet.synsets(word)\n",
    "        for synset in synsets:\n",
    "            # Add synonyms of the word from each synset to the set\n",
    "            synonyms.update([lemma.name() for lemma in synset.lemmas()])\n",
    "    return synonyms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonym set: \n",
      "{'lightheaded', 'kip', 'nap', 'chill', 'rock', 'pyrexia', 'shake_off', 'quivering', 'thrill', 'throb', 'sick_headache', 'cephalalgia', 'quietus', 'vertiginous', 'rest', 'worry', 'shiver', 'febricity', 'sopor', 'empty-headed', 'silly', 'vexation', \"log_Z's\", 'airheaded', 'judder', 'sway', 'throw_off', 'shaky', 'agitate', 'shivering', 'feverishness', 'shudder', 'febrility', 'sleep', 'shaking', 'didder', 'stir', 'giddy', 'headache', 'palpitation', 'eternal_rest', 'excite', 'fever', 'migraine', 'hemicrania', \"catch_some_Z's\", 'shake', 'quiver', 'trembling', 'woozy', 'concern', 'megrim', 'vibration', 'light-headed', 'featherbrained', 'dizzy', 'slumber', 'shake_up', 'escape_from', 'eternal_sleep', 'stimulate', 'shakiness', 'head_ache'}\n",
      "\n",
      "List of all symptoms: \n",
      "['lightheaded', 'kip', 'nap', 'chill', 'rock', 'pyrexia', 'shake_off', 'quivering', 'thrill', 'throb', 'sick_headache', 'cephalalgia', 'quietus', 'vertiginous', 'rest', 'worry', 'shiver', 'febricity', 'sopor', 'empty-headed', 'silly', 'vexation', \"log_Z's\", 'airheaded', 'judder', 'sway', 'throw_off', 'shaky', 'agitate', 'shivering', 'feverishness', 'shudder', 'febrility', 'sleep', 'shaking', 'didder', 'stir', 'giddy', 'headache', 'palpitation', 'eternal_rest', 'excite', 'fever', 'migraine', 'hemicrania', \"catch_some_Z's\", 'shake', 'quiver', 'trembling', 'woozy', 'concern', 'megrim', 'vibration', 'light-headed', 'featherbrained', 'dizzy', 'slumber', 'shake_up', 'escape_from', 'eternal_sleep', 'stimulate', 'shakiness', 'head_ache']\n"
     ]
    }
   ],
   "source": [
    "synonyms = get_synonyms(keywords)\n",
    "print(\"Synonym set: \")\n",
    "print(synonyms)\n",
    "print()\n",
    "\n",
    "print(\"List of all symptoms: \")\n",
    "final_symptoms = list(synonyms)\n",
    "print(final_symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "# Function to find the closest match using Levenshtein distance for final list of symptoms compared to the dataset symptoms\n",
    "# currently unimplemented as we haven't found a good way to make it work\n",
    "def find_closest_match(word):\n",
    "    closest_match = min(dataset_symptoms, key=lambda w: Levenshtein.distance(word, w))\n",
    "    return closest_match\n",
    "\n",
    "# Function to extract relevant symptoms based on Levenshtein distance\n",
    "def extract_relevant_symptoms(final_symptoms):\n",
    "    relevant_symptoms = []\n",
    "    for sym in final_symptoms:\n",
    "        # closest_match = find_closest_match(sym)\n",
    "        if sym in dataset_symptoms:\n",
    "            relevant_symptoms.append(sym)\n",
    "        # relevant_symptoms.append(closest_match)\n",
    "    return relevant_symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chill', 'shivering', 'shaking', 'headache', 'fever', 'shakiness']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_relevant_symptoms(final_symptoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible future implementations for Preprocessing:\n",
    "\n",
    "Look for symptom phrases to develop / inference a more descriptive symptom. Some keywords may not mean much on their own, but the words around them give more meaning. For example the word \"sleep,\" the complete phrase may be \"I can't sleep\" or \"I have trouble sleeping.\" To get the full picture we can look at words preceding and following the symptom keyword. \n",
    "\n",
    "_ _ _ sleep\n",
    "\n",
    "sleep _ _ _\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting different forms of the symptom keywords\n",
    "\n",
    "We can increase chances of finding the right symptoms just by changing the form of the word used. Ex. \"sleepy\" to \"sleepiness\". But there are currently no libraries that can do this accurately and coding this up would take a lot of time which is beyond the scope of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sleepe',\n",
       " 'sleeped',\n",
       " 'sleepes',\n",
       " 'sleeping',\n",
       " 'sleepful',\n",
       " 'sleepness',\n",
       " 'sleepfulness']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all forms of the extracted symptoms\n",
    "# i.e. 'sleep' --> 'sleepy', 'sleepiness', 'sleep'\n",
    "#\n",
    "# !pip install reversestem\n",
    "\n",
    "from reversestem import unstem\n",
    "\n",
    "unstem('sleep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Models\n",
    "\n",
    "Classification models used to match an input list of symptoms to the disease.\n",
    "\n",
    "Following code inspired by this github repo: https://github.com/rahul15197/Disease-Detection-based-on-Symptoms?source=post_page-----54e6be60a3d1--------------------------------\n",
    "\n",
    "We used the dataset from the github repo as well as some general structure of code. Most of the code was written by us to suit our overall structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists used for performance plots\n",
    "\n",
    "model_list = []\n",
    "f1_scores = []\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/content/en_medical_dialog.json'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "symptoms_dataset = pd.read_csv(\"Dataset/dis_sym_dataset_comb.csv\")\n",
    "\n",
    "# separate the features and labels\n",
    "X = symptoms_dataset.iloc[:, 1:]\n",
    "Y = symptoms_dataset.iloc[:, 0:1]\n",
    "\n",
    "# convert Y (labels) to a 1D array \n",
    "y_array = Y.to_numpy() if isinstance(Y, pd.Series) else Y.values\n",
    "Y = y_array.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.10)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model according to its type and make predictions\n",
    "def fit_and_predict(classifier, model_type):\n",
    "    classifier = classifier.fit(X, Y)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    \n",
    "    precision, recall, f1, accuracy = evaluate_model(y_test, y_pred, model_type)\n",
    "    print_evaluation_metrics(precision, recall, f1, accuracy)\n",
    "\n",
    "# Evaluate the model on different metrics\n",
    "def evaluate_model(y_test, y_pred, model_type):\n",
    "    # Calculate precision, recall, and F1-score for each class and then compute the macro average\n",
    "    precision = round(Decimal(precision_score(y_test, y_pred, average='macro', zero_division=1) * 100), 2)\n",
    "    recall= round(Decimal(recall_score(y_test, y_pred, average='macro', zero_division=1) * 100), 2)\n",
    "    f1= round(Decimal(f1_score(y_test, y_pred, average='macro') * 100), 2)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    accuracy = round(Decimal(accuracy_score(y_test, y_pred) * 100), 2)\n",
    "    \n",
    "    # Add metrics to overall arrays used later for graphing\n",
    "    model_list.append(model_type)\n",
    "    f1_scores.append(f1)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    return precision, recall, f1, accuracy\n",
    "    \n",
    "def print_evaluation_metrics(precision, recall, f1, accuracy):\n",
    "    print(f'Macro-average Precision: {precision}%')\n",
    "    print(f'Macro-average Recall: {recall}%')\n",
    "    print(f'Macro-average F1-score: {f1}%')\n",
    "    print(f'Accuracy: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints all model names and their f1 score and accuracy\n",
    "def print_all_metrics():\n",
    "    for i in range(len(model_list)):\n",
    "        print(f'Model: {model_list[i]}, f1 = {f1_scores[i]} accuracy = {accuracies[i]}')\n",
    "        # print(model_list[i], f1_scores[i], accuracies[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Naive Bayes classifier\n",
    "mnb = MultinomialNB()\n",
    "fit_and_predict(mnb, 'MultinomialNaiveBayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Support Vector Machine classifier\n",
    "svm = SVC()\n",
    "fit_and_predict(svm, 'SupportVectorMachine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Support Vector Machine classifier\n",
    "lr = LogisticRegression()\n",
    "fit_and_predict(lr, 'LogisticRegression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics and Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric lists for reference\n",
    "# model_list = []\n",
    "# f1_scores = []\n",
    "# accuracies = []\n",
    "\n",
    "# Comparison plot for all classifiers with their accuracy\n",
    "plt.style.use('_classic_test_patch')\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot()\n",
    "plt.title(\"Model Vs Accuracy\", color='black', pad=30)\n",
    "plt.xlabel('Classifier', color='black')\n",
    "plt.ylabel('Accuracy (%)', color='black')\n",
    "plt.bar(model_list, accuracies, color='lightblue')\n",
    "for i, j in enumerate(accuracies):\n",
    "    ax.text(float(i)-0.15, float(j)+0.7, str(j), color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison plot for all classifiers with their F1-score\n",
    "plt.style.use('_classic_test_patch')\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot()\n",
    "plt.title(\"Model Vs F1-score\", color='black', pad=30)\n",
    "plt.xlabel('Classifier', color='black')\n",
    "plt.ylabel('F1-score (%)', color='black')\n",
    "plt.bar(model_list, f1_scores, color='lightblue')\n",
    "for i, j in enumerate(f1_scores):\n",
    "    ax.text(float(i)-0.15, float(j)+0.7, str(j), color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MedicalAnalyzer for Disease Output\n",
    "\n",
    "This is the main user-model interactive section, all the above code needs to be run so that the following works. This is the minimalist and to the point interaction between user and our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model\n",
    "\n",
    "The best performing model was Logistic Regression, so we'll use that in our evaluations of user input.\n",
    "\n",
    "This code almost completely adapted from: https://github.com/rahul15197/Disease-Detection-based-on-Symptoms/blob/master/SymptomSuggestion.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df_comb = pd.read_csv(\"Dataset/dis_sym_dataset_comb.csv\")\n",
    "df_norm = pd.read_csv(\"Dataset/dis_sym_dataset_norm.csv\")\n",
    "\n",
    "# separate the features and labels\n",
    "X = df_comb.iloc[:, 1:]\n",
    "Y = df_comb.iloc[:, 0:1]\n",
    "\n",
    "# convert Y (labels) to a 1D array \n",
    "y_array = Y.to_numpy() if isinstance(Y, pd.Series) else Y.values\n",
    "Y = y_array.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr = lr.fit(X, Y)\n",
    "scores = cross_val_score(lr, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_norm.iloc[:, 1:]\n",
    "Y = df_norm.iloc[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of symptoms\n",
    "dataset_symptoms = list(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Symptoms --> Disease\n",
    "\n",
    "This is where we use the model to tell us what diseases the user may have based on the symptoms extracted from their input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector from processed user symptoms to be used by the model\n",
    "\n",
    "# example symptom list\n",
    "# sym_list = [\"yellowish skin\",\"wheezing\",\"abdominal cramp\",\"back\",\"feeling cold\"]\n",
    "\n",
    "def create_symptom_vector(sym_list):\n",
    "    sym_vector = [0 for i in range(0, len(dataset_symptoms))]\n",
    "    for sym in sym_list:\n",
    "        # print(sym)\n",
    "        sym_vector[dataset_symptoms.index(sym)] = 1\n",
    "    return sym_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the likelihood for each disease\n",
    "diseases = list(set(Y['label_dis']))\n",
    "diseases.sort()\n",
    "def predict_diseases(sym_vector):\n",
    "    disease_predict = lr.predict_proba([sym_vector])\n",
    "    k = 10\n",
    "    top_k = disease_predict[0].argsort()[-k:][::-1]\n",
    "    return top_k, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates top k diseases that match the symptom list vector and prints out the name of the disease along with how likely it is that disease\n",
    "\n",
    "def output_top_k_diseases(top_k, k, sym_list):\n",
    "    print(f\"\\nTop {k} diseases predicted based on symptoms\")\n",
    "    topk_dict = {}\n",
    "    # Show top 10 highly probable disease to the user.\n",
    "    for idx,t in  enumerate(top_k):\n",
    "        match_sym=set()\n",
    "        row = df_norm.loc[df_norm['label_dis'] == diseases[t]].values.tolist()\n",
    "        row[0].pop(0)\n",
    "    \n",
    "        for idx,val in enumerate(row[0]):\n",
    "            if val!=0:\n",
    "                match_sym.add(dataset_symptoms[idx])\n",
    "        prob = (len(match_sym.intersection(set(sym_list)))+1)/(len(set(sym_list))+1)\n",
    "        prob *= np.mean(scores)\n",
    "        topk_dict[t] = prob\n",
    "    j = 0\n",
    "    topk_index_mapping = {}\n",
    "    topk_sorted = dict(sorted(topk_dict.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    for key in topk_sorted:\n",
    "        prob = topk_sorted[key]*100\n",
    "\n",
    "        # number_dis = f\"{str(j+1):<2}\"\n",
    "        # disease_name = f\"{diseases[key]:<10}\"\n",
    "        # probability_of_dis = f\"{str(round(prob, 2)):<30}\"\n",
    "        # # prob = f\"Probability::<20\"\n",
    "        \n",
    "        print(str(j+1) + \" Disease name:\",diseases[key], \"\\tProbability:\",str(round(prob, 2))+\"%\")\n",
    "     \n",
    "        topk_index_mapping[j] = key\n",
    "        j += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-interactable Interface\n",
    "\n",
    "Note: In actual implementation the user wouldn't get the list of diseases shown to them, it would instead be saved to a file and shown to the doctor. This implementation is created to show all of the output in one place to see how the model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example user input\n",
    "# user_input = \"I have been having migraines and headaches. I can't sleep. My whole body is shaking and shivering. I feel dizzy sometimes. I have a fever.\"\n",
    "# new_user_input = normalize_user_input(user_input)\n",
    "def MedicalAnalyzer():\n",
    "    new_user_input = user_input()\n",
    "    print()\n",
    "    \n",
    "    # Extract symptoms\n",
    "    symptoms = extract_symptoms(new_user_input)\n",
    "    \n",
    "    # Clean and join the tokens into keywords\n",
    "    keywords = clean_keywords(symptoms)\n",
    "    \n",
    "    # Display the symptoms\n",
    "    print(\"Key symptom words: \", keywords)\n",
    "    print()\n",
    "    \n",
    "    # Display all symptoms including synonyms\n",
    "    synonyms = get_synonyms(keywords)\n",
    "    final_symptoms = list(synonyms)\n",
    "    print(\"Symptoms synonyms list: \", final_symptoms)\n",
    "    print()\n",
    "    \n",
    "    # Get relevant symptoms\n",
    "    relevant_symptoms = extract_relevant_symptoms(final_symptoms)\n",
    "    \n",
    "    print(\"Final symptoms list: \", relevant_symptoms)\n",
    "    print()\n",
    "    \n",
    "    # Create a vector to be used by the model\n",
    "    sym_vector = create_symptom_vector(relevant_symptoms)\n",
    "    \n",
    "    # Get top diseases\n",
    "    topk_diseases, k = predict_diseases(sym_vector)\n",
    "    \n",
    "    output_top_k_diseases(topk_diseases, k, relevant_symptoms)\n",
    "# Hi doctor, I am a 26 year old male. I am 5 feet and 9 inches tall and weigh 255 pounds. When I eat spicy food, I poop blood. Sometimes when I have constipation as well, I poop a little bit of blood. I am really scared that I have colon cancer. I do have diarrhea often. I do not have a family history of colon cancer. I got blood tests done last night. Please find my reports attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter symptoms: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Hi doctor, I am a 26 year old male. I am 5 feet and 9 inches tall and weigh 255 pounds. When I eat spicy food, I poop blood. Sometimes when I have constipation as well, I poop a little bit of blood. I am really scared that I have colon cancer. I do have diarrhea often. I do not have a family history of colon cancer. I got blood tests done last night. Please find my reports attached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Key symptom words:  ['constipation', 'scared', 'diarrhea', 'constipation', 'diarrhea']\n",
      "\n",
      "Symptoms synonyms list:  ['constipation', 'stultification', 'looseness_of_the_bowels', 'impairment', 'affright', 'irregularity', 'frightened', 'scare', 'daunt', 'scare_off', 'mark', 'scar', 'diarrhea', 'fright', 'frighten', 'pit', 'frighten_away', 'dash', 'diarrhoea', 'scare_away', 'pall', 'looseness', 'deadening', 'scared', 'pock', 'frighten_off']\n",
      "\n",
      "Final symptoms list:  ['constipation', 'diarrhea', 'diarrhoea']\n",
      "\n",
      "\n",
      "Top 10 diseases predicted based on symptoms\n",
      "1 Disease name: Celiacs disease \tProbability: 66.89%\n",
      "2 Disease name: Irritable bowel syndrome \tProbability: 66.89%\n",
      "3 Disease name: Ebola \tProbability: 44.6%\n",
      "4 Disease name: Hyperthyroidism \tProbability: 44.6%\n",
      "5 Disease name: Porphyria \tProbability: 44.6%\n",
      "6 Disease name: Lead poisoning \tProbability: 44.6%\n",
      "7 Disease name: Hypothyroid \tProbability: 44.6%\n",
      "8 Disease name: Anthrax \tProbability: 44.6%\n",
      "9 Disease name: lactose intolerance \tProbability: 44.6%\n",
      "10 Disease name: Crimean Congo haemorrhagic fever (CCHF) \tProbability: 44.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MedicalAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlf4P1apdf-w"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "# Define a class to store a single sentiment example\n",
    "class SentimentExample:\n",
    "    def __init__(self, words, label):\n",
    "        self.words = words\n",
    "        self.label = label\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(self.words) + \"; label=\" + repr(self.label)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "\n",
    "\n",
    "# Reads sentiment examples in the format [0 or 1]<TAB>[raw sentence]; tokenizes and cleans the sentences.\n",
    "def read_sentiment_examples(infile):\n",
    "    f = open(infile, encoding='iso8859')\n",
    "    exs = []\n",
    "    for line in f:\n",
    "            fields = line.strip().split(\".\")\n",
    "            label = 0 if \"0\" in fields[0] else 1\n",
    "            exs.append(SentimentExample(fields[1:], label))\n",
    "    f.close()\n",
    "    return exs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2cvJYNyjlOy",
    "outputId": "7827d0b6-258e-4a12-e177-fc015f7602ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383740 train examples: 1248305 positive, 135435 negative\n"
     ]
    }
   ],
   "source": [
    "train_file = '/content/en_medical_dialog.json'\n",
    "\n",
    "# Load the data from the files\n",
    "train_exs = read_sentiment_examples(train_file)\n",
    "n_pos = 0\n",
    "n_neg = 0\n",
    "for ex in train_exs:\n",
    "    if ex.label == 1:\n",
    "        n_pos += 1\n",
    "    else:\n",
    "        n_neg += 1\n",
    "print(\"%d train examples: %d positive, %d negative\" % (len(train_exs), n_pos, n_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CF_-Glv3bVAC",
    "outputId": "130195e4-286b-41e7-8acc-4fa43990bf76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnose_en_dataset.feather  en_medical_dialog.json  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxnRHPTUbYji"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "OTVbCkZ9rAgC",
    "outputId": "a406545b-3215-471b-c1b6-cd32460b2359"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-50a59f59-7727-493c-afe7-48c7a3f4be4a\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Description</th>\n",
       "      <th>Doctor</th>\n",
       "      <th>Patient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Q. What does abutment of the nerve root mean?</td>\n",
       "      <td>Hi. I have gone through your query with dilige...</td>\n",
       "      <td>Hi doctor,I am just wondering what is abutting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Q. Every time I eat spicy food, I poop blood. ...</td>\n",
       "      <td>Hello. I have gone through your information an...</td>\n",
       "      <td>Hi doctor, I am a 26 year old male. I am 5 fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Q. Will Nano-Leo give permanent solution for e...</td>\n",
       "      <td>Hi. For further doubts consult a sexologist on...</td>\n",
       "      <td>Hello doctor, I am 48 years old. I am experien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Q. Will Kalarchikai cure multiple ovarian cyst...</td>\n",
       "      <td>Hello. I just read your query. See Kalarachi K...</td>\n",
       "      <td>Hello doctor, I have multiple small cysts in b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Q. I masturbate only by rubbing the tip of the...</td>\n",
       "      <td>Hi. For further doubts consult a sexologist on...</td>\n",
       "      <td>Hi doctor, During masturbation I just rub the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50a59f59-7727-493c-afe7-48c7a3f4be4a')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-50a59f59-7727-493c-afe7-48c7a3f4be4a button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-50a59f59-7727-493c-afe7-48c7a3f4be4a');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-e4f0bf4d-2568-48c0-b54d-c1793c3e61ae\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e4f0bf4d-2568-48c0-b54d-c1793c3e61ae')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-e4f0bf4d-2568-48c0-b54d-c1793c3e61ae button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   id                                        Description  \\\n",
       "0   0      Q. What does abutment of the nerve root mean?   \n",
       "1   1  Q. Every time I eat spicy food, I poop blood. ...   \n",
       "2   2  Q. Will Nano-Leo give permanent solution for e...   \n",
       "3   3  Q. Will Kalarchikai cure multiple ovarian cyst...   \n",
       "4   4  Q. I masturbate only by rubbing the tip of the...   \n",
       "\n",
       "                                              Doctor  \\\n",
       "0  Hi. I have gone through your query with dilige...   \n",
       "1  Hello. I have gone through your information an...   \n",
       "2  Hi. For further doubts consult a sexologist on...   \n",
       "3  Hello. I just read your query. See Kalarachi K...   \n",
       "4  Hi. For further doubts consult a sexologist on...   \n",
       "\n",
       "                                             Patient  \n",
       "0  Hi doctor,I am just wondering what is abutting...  \n",
       "1  Hi doctor, I am a 26 year old male. I am 5 fee...  \n",
       "2  Hello doctor, I am 48 years old. I am experien...  \n",
       "3  Hello doctor, I have multiple small cysts in b...  \n",
       "4  Hi doctor, During masturbation I just rub the ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_feather(\"diagnose_en_dataset.feather\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "daTqy3L6rdlu",
    "outputId": "1b40cea8-c8b6-422f-da3d-029e2f9d273a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 257469 entries, 0 to 257468\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   id           257469 non-null  int64 \n",
      " 1   Description  257469 non-null  object\n",
      " 2   Doctor       257469 non-null  object\n",
      " 3   Patient      257469 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 7.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ribNe71ruLQg",
    "outputId": "18eee90f-4071-4182-a68c-ff4fe899e055"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-bc64718b-4a9f-41d8-96b2-db32bf8b5d93\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Doctor</th>\n",
       "      <th>Patient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q. What does abutment of the nerve root mean?</td>\n",
       "      <td>Hi. I have gone through your query with dilige...</td>\n",
       "      <td>Hi doctor,I am just wondering what is abutting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q. Every time I eat spicy food, I poop blood. ...</td>\n",
       "      <td>Hello. I have gone through your information an...</td>\n",
       "      <td>Hi doctor, I am a 26 year old male. I am 5 fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q. Will Nano-Leo give permanent solution for e...</td>\n",
       "      <td>Hi. For further doubts consult a sexologist on...</td>\n",
       "      <td>Hello doctor, I am 48 years old. I am experien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q. Will Kalarchikai cure multiple ovarian cyst...</td>\n",
       "      <td>Hello. I just read your query. See Kalarachi K...</td>\n",
       "      <td>Hello doctor, I have multiple small cysts in b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q. I masturbate only by rubbing the tip of the...</td>\n",
       "      <td>Hi. For further doubts consult a sexologist on...</td>\n",
       "      <td>Hi doctor, During masturbation I just rub the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc64718b-4a9f-41d8-96b2-db32bf8b5d93')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-bc64718b-4a9f-41d8-96b2-db32bf8b5d93 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-bc64718b-4a9f-41d8-96b2-db32bf8b5d93');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-8bbfccd5-1f97-413e-83a2-46341e194a56\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8bbfccd5-1f97-413e-83a2-46341e194a56')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-8bbfccd5-1f97-413e-83a2-46341e194a56 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                         Description  \\\n",
       "0      Q. What does abutment of the nerve root mean?   \n",
       "1  Q. Every time I eat spicy food, I poop blood. ...   \n",
       "2  Q. Will Nano-Leo give permanent solution for e...   \n",
       "3  Q. Will Kalarchikai cure multiple ovarian cyst...   \n",
       "4  Q. I masturbate only by rubbing the tip of the...   \n",
       "\n",
       "                                              Doctor  \\\n",
       "0  Hi. I have gone through your query with dilige...   \n",
       "1  Hello. I have gone through your information an...   \n",
       "2  Hi. For further doubts consult a sexologist on...   \n",
       "3  Hello. I just read your query. See Kalarachi K...   \n",
       "4  Hi. For further doubts consult a sexologist on...   \n",
       "\n",
       "                                             Patient  \n",
       "0  Hi doctor,I am just wondering what is abutting...  \n",
       "1  Hi doctor, I am a 26 year old male. I am 5 fee...  \n",
       "2  Hello doctor, I am 48 years old. I am experien...  \n",
       "3  Hello doctor, I have multiple small cysts in b...  \n",
       "4  Hi doctor, During masturbation I just rub the ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns='id', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3bolKkDbZGo"
   },
   "source": [
    "# TEST WRITING\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
