{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/isaashka/NLPMedicalAnalyzer/blob/main/NLPMedicalAnalyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3CLxyK4kjm0"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 15:04:23.060 Python[27475:135143] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FzF6mi4KbJWs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/sasha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/sasha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General imports\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.probability import FreqDist\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model specific imports\n",
    "from decimal import Decimal\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from nltk.util import ngrams\n",
    "import math\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unused\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSDZHGxxbS4O"
   },
   "source": [
    "# Data Preprocessing\n",
    "### Goal: convert user input --> symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "symptoms_dataset = pd.read_csv(\"Dataset/dis_sym_dataset_comb.csv\")\n",
    "\n",
    "# extract features to use as a symptom array\n",
    "X = symptoms_dataset.iloc[:, 1:]\n",
    "dataset_symptoms = list(X.columns)\n",
    "# dataset_symptoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_input():\n",
    "    print(\"Enter symptoms: \")\n",
    "    user_input = input()\n",
    "    normalize_user_input(user_input)\n",
    "\n",
    "def correct_spelling(user_input):\n",
    "    spell = SpellChecker()\n",
    "    words = user_input.split()\n",
    "    corrected_words = [spell.correction(word) for word in words]\n",
    "    return ' '.join(corrected_words)\n",
    "\n",
    "def normalize_user_input(user_input):\n",
    "    # lowercase\n",
    "    normalized_input = user_input.lower()\n",
    "    # fix contractions\n",
    "    normalized_input = contractions.fix(normalized_input)\n",
    "    # get rid of punctuation\n",
    "    normalized_input = re.sub(r'[^\\w\\s]', '', normalized_input)\n",
    "\n",
    "    normalized_input = correct_spelling(normalized_input)\n",
    "    \n",
    "    print(normalized_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngram approach\n",
    "\n",
    "Test input: I have been having migraines and headaches. I can't sleep. My whole body is shaking and shivering. I feel dizzy sometimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_symptom_phrases(tokens, symptom_keywords, body_parts, n=2):\n",
    "    symptom_phrases = []\n",
    "    ngrams_list = list(ngrams(tokens, n))\n",
    "\n",
    "    for ngram in ngrams_list:\n",
    "        for keyword in symptom_keywords:\n",
    "            for body_part in body_parts:\n",
    "                if keyword in ngram and body_part in ngram:\n",
    "                    symptom_phrases.append(' '.join(ngram))\n",
    "\n",
    "    return symptom_phrases\n",
    "\n",
    "# Lemmatize input\n",
    "def lemmatize_tokens(tokens):\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    lemmatized_tokens = []  \n",
    "    for token in tokens:\n",
    "        lemmatized_tokens.append(lemmatizer.lemmatize(token))\n",
    "    return lemmatized_tokens\n",
    "\n",
    "def tokenize_user_symptoms():\n",
    "    print(\"Enter symptoms: \")\n",
    "    \n",
    "    symptoms = input()\n",
    "    # tokenize input\n",
    "    symptom_tokens = word_tokenize(symptoms)\n",
    "\n",
    "    # lemmatize input\n",
    "    symptom_tokens_lemmatized = lemmatize_tokens(symptom_tokens)\n",
    "\n",
    "    # find symptom phrases using n-grams\n",
    "    symptom_phrases = find_symptom_phrases(symptom_tokens_lemmatized, \\\n",
    "                                           dataset_symptoms, dataset_symptoms) # dataset_symptoms = symptoms retrieved from the dataset\n",
    "    \n",
    "    return symptom_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter symptoms: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I have been having migraines and headaches. I can't sleep. My whole body is shaking and shivering. I feel dizzy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here's your list of symptoms: \n",
      "['and headache', 'headache .', 'is shaking', 'shaking and', 'and shivering', 'shivering .']\n"
     ]
    }
   ],
   "source": [
    "extracted_symptoms = tokenize_user_symptoms()\n",
    "print()\n",
    "print('Here\\'s your list of symptoms: ')\n",
    "print(extracted_symptoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER / BERT approach --- WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting textsearch>=0.0.21 (from contractions)\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
      "  Downloading pyahocorasick-2.1.0-cp310-cp310-macosx_10_9_x86_64.whl.metadata (13 kB)\n",
      "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyahocorasick-2.1.0-cp310-cp310-macosx_10_9_x86_64.whl (37 kB)\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "import re\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot believe it is not butter! She will not be coming, and he is not happy about it.\n"
     ]
    }
   ],
   "source": [
    "# Define a function to replace contractions\n",
    "def replace_contractions_contractions_lib(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "# Example usage\n",
    "text = \"I can't believe it's not butter! She won't be coming, and he's not happy about it.\"\n",
    "normalized_text = replace_contractions_contractions_lib(text)\n",
    "print(normalized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter symptoms: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " HELLOO. yess, can't omg... we'll!!! smthing miesspelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello less cannot om we will something misspelled\n"
     ]
    }
   ],
   "source": [
    "user_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "Classification models used to match an input list of symptoms to the disease.\n",
    "\n",
    "Following code inspired by this github repo: https://github.com/rahul15197/Disease-Detection-based-on-Symptoms?source=post_page-----54e6be60a3d1--------------------------------\n",
    "\n",
    "We used the dataset from the github repo as well as some general structure of code. Most of the code was written by us to suit our overall structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists used for performance plots\n",
    "\n",
    "model_list = []\n",
    "f1_scores = []\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "symptoms_dataset = pd.read_csv(\"Dataset/dis_sym_dataset_comb.csv\")\n",
    "\n",
    "# separate the features and labels\n",
    "X = symptoms_dataset.iloc[:, 1:]\n",
    "Y = symptoms_dataset.iloc[:, 0:1]\n",
    "\n",
    "# convert Y (labels) to a 1D array \n",
    "y_array = Y.to_numpy() if isinstance(Y, pd.Series) else Y.values\n",
    "Y = y_array.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.10)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model according to its type and make predictions\n",
    "def fit_and_predict(classifier, model_type):\n",
    "    classifier = classifier.fit(X, Y)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    \n",
    "    precision, recall, f1, accuracy = evaluate_model(y_test, y_pred, model_type)\n",
    "    print_evaluation_metrics(precision, recall, f1, accuracy)\n",
    "\n",
    "# Evaluate the model on different metrics\n",
    "def evaluate_model(y_test, y_pred, model_type):\n",
    "    # Calculate precision, recall, and F1-score for each class and then compute the macro average\n",
    "    precision = round(Decimal(precision_score(y_test, y_pred, average='macro', zero_division=1) * 100), 2)\n",
    "    recall= round(Decimal(recall_score(y_test, y_pred, average='macro', zero_division=1) * 100), 2)\n",
    "    f1= round(Decimal(f1_score(y_test, y_pred, average='macro') * 100), 2)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    accuracy = round(Decimal(accuracy_score(y_test, y_pred) * 100), 2)\n",
    "    \n",
    "    # Add metrics to overall arrays used later for graphing\n",
    "    model_list.append(model_type)\n",
    "    f1_scores.append(f1)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    return precision, recall, f1, accuracy\n",
    "    \n",
    "def print_evaluation_metrics(precision, recall, f1, accuracy):\n",
    "    print(f'Macro-average Precision: {precision}%')\n",
    "    print(f'Macro-average Recall: {recall}%')\n",
    "    print(f'Macro-average F1-score: {f1}%')\n",
    "    print(f'Accuracy: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints all model names and their f1 score and accuracy\n",
    "def print_all_metrics():\n",
    "    for i in range(len(model_list)):\n",
    "        print(f'Model: {model_list[i]}, f1 = {f1_scores[i]} accuracy = {accuracies[i]}')\n",
    "        # print(model_list[i], f1_scores[i], accuracies[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Naive Bayes classifier\n",
    "mnb = MultinomialNB()\n",
    "fit_and_predict(mnb, 'MultinomialNaiveBayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Support Vector Machine classifier\n",
    "svm = SVC()\n",
    "fit_and_predict(svm, 'SupportVectorMachine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Support Vector Machine classifier\n",
    "lr = LogisticRegression()\n",
    "fit_and_predict(lr, 'LogisticRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric lists for reference\n",
    "# model_list = []\n",
    "# f1_scores = []\n",
    "# accuracies = []\n",
    "\n",
    "# Comparison plot for all classifiers with their accuracy\n",
    "plt.style.use('_classic_test_patch')\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot()\n",
    "plt.title(\"Model Vs Accuracy\", color='black', pad=30)\n",
    "plt.xlabel('Classifier', color='black')\n",
    "plt.ylabel('Accuracy (%)', color='black')\n",
    "plt.bar(model_list, accuracies, color='lightblue')\n",
    "for i, j in enumerate(accuracies):\n",
    "    ax.text(float(i)-0.15, float(j)+0.7, str(j), color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison plot for all classifiers with their F1-score\n",
    "plt.style.use('_classic_test_patch')\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot()\n",
    "plt.title(\"Model Vs F1-score\", color='black', pad=30)\n",
    "plt.xlabel('Classifier', color='black')\n",
    "plt.ylabel('F1-score (%)', color='black')\n",
    "plt.bar(model_list, f1_scores, color='lightblue')\n",
    "for i, j in enumerate(f1_scores):\n",
    "    ax.text(float(i)-0.15, float(j)+0.7, str(j), color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model\n",
    "\n",
    "The best performing model was Logistic Regression, so we'll use that in our evaluations of user input.\n",
    "\n",
    "This code almost completely adapted from: https://github.com/rahul15197/Disease-Detection-based-on-Symptoms/blob/master/SymptomSuggestion.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df_comb = pd.read_csv(\"Dataset/dis_sym_dataset_comb.csv\")\n",
    "df_norm = pd.read_csv(\"Dataset/dis_sym_dataset_norm.csv\")\n",
    "\n",
    "# separate the features and labels\n",
    "X = df_comb.iloc[:, 1:]\n",
    "Y = df_comb.iloc[:, 0:1]\n",
    "\n",
    "# convert Y (labels) to a 1D array \n",
    "y_array = Y.to_numpy() if isinstance(Y, pd.Series) else Y.values\n",
    "Y = y_array.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr = lr.fit(X, Y)\n",
    "scores = cross_val_score(lr, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_norm.iloc[:, 1:]\n",
    "Y = df_norm.iloc[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of symptoms\n",
    "dataset_symptoms = list(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Symptoms --> Disease\n",
    "\n",
    "This is where we use the model to tell us what diseases the user may have based on the symptoms extracted from their input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector from processed user symptoms to be used by the model\n",
    "\n",
    "# example symptom list\n",
    "sym_list = [\"yellowish skin\",\"wheezing\",\"abdominal cramp\",\"back\",\"feeling cold\"]\n",
    "\n",
    "sym_vector = [0 for i in range(0, len(dataset_symptoms))]\n",
    "for sym in sym_list:\n",
    "    print(sym)\n",
    "    sym_vector[dataset_symptoms.index(sym)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_predict = lr.predict_proba([sym_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "diseases = list(set(Y['label_dis']))\n",
    "diseases.sort()\n",
    "top_k = disease_predict[0].argsort()[-k:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"\\nTop {k} diseases predicted based on symptoms\")\n",
    "topk_dict = {}\n",
    "# Show top 10 highly probable disease to the user.\n",
    "for idx,t in  enumerate(top_k):\n",
    "    match_sym=set()\n",
    "    row = df_norm.loc[df_norm['label_dis'] == diseases[t]].values.tolist()\n",
    "    row[0].pop(0)\n",
    "\n",
    "    for idx,val in enumerate(row[0]):\n",
    "        if val!=0:\n",
    "            match_sym.add(dataset_symptoms[idx])\n",
    "    prob = (len(match_sym.intersection(set(sym_list)))+1)/(len(set(sym_list))+1)\n",
    "    prob *= np.mean(scores)\n",
    "    topk_dict[t] = prob\n",
    "j = 0\n",
    "topk_index_mapping = {}\n",
    "topk_sorted = dict(sorted(topk_dict.items(), key=lambda kv: kv[1], reverse=True))\n",
    "for key in topk_sorted:\n",
    "  prob = topk_sorted[key]*100\n",
    "  print(str(j+1) + \" Disease name:\",diseases[key], \"\\tProbability:\",str(round(prob, 2))+\"%\")\n",
    "  topk_index_mapping[j] = key\n",
    "  j += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
