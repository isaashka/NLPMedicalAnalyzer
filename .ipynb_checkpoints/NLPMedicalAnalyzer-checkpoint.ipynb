{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/isaashka/NLPMedicalAnalyzer/blob/main/NLPMedicalAnalyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3CLxyK4kjm0"
   },
   "source": [
    "# Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "FzF6mi4KbJWs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/sasha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/sasha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.probability import FreqDist\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 14:23:10.148 Python[1831:32516] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSDZHGxxbS4O"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer class\n",
    "\n",
    "class Tokenizer:\n",
    "  def __init__(self, lowercase=False):\n",
    "    self.lowercase = lowercase  # If this is True, convert text to lowercase while tokenizing.\n",
    "    self.vocab = []\n",
    "\n",
    "  def tokenize(self, string):\n",
    "    tokens = word_tokenize(string)\n",
    "    self.vocab += [w for w in set(tokens) if w not in self.vocab]\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "JEI2eAWjbmuu"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Tell me about your symptoms:  hey tokens aaa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hey', 'tokens', 'aaa']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#User input\n",
    "tokenizer = Tokenizer(lowercase = True) \n",
    "user_input = input(\"Tell me about your symptoms: \")\n",
    "\n",
    "tokens = tokenizer.tokenize(user_input)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['running', 'swimming', 'better', 'child', 'easily', 'faster']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Example usage\n",
    "words = ['running', 'swimming', 'better', 'children', 'easily', 'faster']\n",
    "\n",
    "# Lemmatize each word\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "# Print the results\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists used for accuracy plots\n",
    "\n",
    "model_list = []\n",
    "f1_scores = []\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "symptoms_dataset = pd.read_csv(\"Dataset/dis_sym_dataset_comb.csv\")\n",
    "\n",
    "# separate the features and labels\n",
    "X = symptoms_dataset.iloc[:, 1:]\n",
    "Y = symptoms_dataset.iloc[:, 0:1]\n",
    "\n",
    "# convert Y (labels) to a 1D array \n",
    "y_array = Y.to_numpy() if isinstance(Y, pd.Series) else Y.values\n",
    "Y = y_array.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.10)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7951, 489)\n",
      "(7951,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)  # Check the shape of X\n",
    "print(y_train.shape)  # Check the shape of y\n",
    "\n",
    "# List of symptoms\n",
    "dataset_symptoms = list(X.columns)\n",
    "# dataset_symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_symptom_phrases(tokens, symptom_keywords, body_parts, n=2):\n",
    "    symptom_phrases = []\n",
    "    ngrams_list = list(ngrams(tokens, n))\n",
    "\n",
    "    for ngram in ngrams_list:\n",
    "        for keyword in symptom_keywords:\n",
    "            for body_part in body_parts:\n",
    "                if keyword in ngram and body_part in ngram:\n",
    "                    symptom_phrases.append(' '.join(ngram))\n",
    "\n",
    "    return symptom_phrases\n",
    "\n",
    "# Lemmatize input\n",
    "def lemmatize_tokens(tokens):\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "    lemmatized_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        lemmatized_tokens.append(lemmatizer.lemmatize(token))\n",
    "        print(f'{token}, ')\n",
    "    # print()\n",
    "    return tokens\n",
    "\n",
    "def tokenize_user_symptoms():\n",
    "    print(\"Enter symptoms: \")\n",
    "    symptoms = input()\n",
    "    # tk = Tokenizer()  # Correctly create an instance of Tokenizer\n",
    "    # Tokenize input\n",
    "    symptom_tokens = word_tokenize(symptoms)\n",
    "\n",
    "    # Lemmatize input\n",
    "    symptom_tokens_lemmatized = lemmatize_tokens(symptom_tokens)\n",
    "    \n",
    "    # Define symptom-related keywords and body parts\n",
    "    # symptom_keywords = [\"hurts\", \"pain\", \"ache\", \"sore\", \"swelling\"]\n",
    "    symptom_keywords = dataset_symptoms\n",
    "    # body_parts = [\"head\", \"leg\", \"arm\", \"stomach\", \"back\", \"chest\", \"throat\"]\n",
    "    body_parts = wn.synsets('body_part')[0]\n",
    "    body_parts_array = body_parts.lemma_names()\n",
    "    \n",
    "    # Find symptom phrases using n-grams\n",
    "    symptom_phrases = find_symptom_phrases(symptom_tokens_lemmatized, symptom_keywords, symptom_keywords)\n",
    "    \n",
    "    return symptom_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter symptoms: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I have been having migraines and headaches. I can't sleep. My whole body is shaking and shivering. I feel dizzy sometimes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I, \n",
      "have, \n",
      "been, \n",
      "having, \n",
      "migraine, \n",
      "and, \n",
      "headache, \n",
      "., \n",
      "I, \n",
      "ca, \n",
      "n't, \n",
      "sleep, \n",
      "., \n",
      "My, \n",
      "whole, \n",
      "body, \n",
      "is, \n",
      "shaking, \n",
      "and, \n",
      "shivering, \n",
      "., \n",
      "I, \n",
      "feel, \n",
      "dizzy, \n",
      "sometimes, \n",
      "['is shaking', 'shaking and', 'and shivering', 'shivering .']\n"
     ]
    }
   ],
   "source": [
    "# I have been having migraines and headaches. I can't sleep. My whole body is shaking and shivering. I feel dizzy sometimes\n",
    "print(tokenize_user_symptoms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['body_part']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_parts = wn.synsets('body_part')[0]\n",
    "body_parts_array = body_parts.lemma_names()\n",
    "body_parts_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\tfinger\n",
      "True\thand\n",
      "True\thead\n",
      "False\tfeet\n",
      "True\tfoot\n",
      "True\thair\n",
      "False\tcat\n",
      "False\tdog\n",
      "False\tfish\n",
      "False\tcabbage\n",
      "False\tknife\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/sasha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "part = wn.synsets('body_part')[0]\n",
    "\n",
    "def is_body_part(candidate):\n",
    "    for ss in wn.synsets(candidate):\n",
    "        # only get those where the synset matches exactly\n",
    "        name = ss.name().split(\".\", 1)[0]\n",
    "        if name != candidate:\n",
    "            continue\n",
    "        hit = part.lowest_common_hypernyms(ss)\n",
    "        if hit and hit[0] == part:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# true things\n",
    "for word in (\"finger\", \"hand\", \"head\", \"feet\", 'foot', 'hair'):\n",
    "    print(is_body_part(word), word, sep=\"\\t\")\n",
    "\n",
    "# false things\n",
    "for word in (\"cat\", \"dog\", \"fish\", \"cabbage\", \"knife\"):\n",
    "    print(is_body_part(word), word, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model according to its type and make predictions\n",
    "def fit_and_predict(classifier, model_type):\n",
    "    classifier = classifier.fit(X, Y)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    \n",
    "    precision, recall, f1, accuracy = evaluate_model(y_test, y_pred, model_type)\n",
    "    print_evaluation_metrics(precision, recall, f1, accuracy)\n",
    "\n",
    "# Evaluate the model on different metrics\n",
    "def evaluate_model(y_test, y_pred, model_type):\n",
    "    # Calculate precision, recall, and F1-score for each class and then compute the macro average\n",
    "    precision = round(Decimal(precision_score(y_test, y_pred, average='macro', zero_division=1) * 100), 2)\n",
    "    recall= round(Decimal(recall_score(y_test, y_pred, average='macro', zero_division=1) * 100), 2)\n",
    "    f1= round(Decimal(f1_score(y_test, y_pred, average='macro') * 100), 2)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    accuracy = round(Decimal(accuracy_score(y_test, y_pred) * 100), 2)\n",
    "    \n",
    "    # Add metrics to overall arrays used later for graphing\n",
    "    model_list.append(model_type)\n",
    "    f1_scores.append(f1)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    return precision, recall, f1, accuracy\n",
    "    \n",
    "def print_evaluation_metrics(precision, recall, f1, accuracy):\n",
    "    print(f'Macro-average Precision: {precision}%')\n",
    "    print(f'Macro-average Recall: {recall}%')\n",
    "    print(f'Macro-average F1-score: {f1}%')\n",
    "    print(f'Accuracy: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints all model names and their f1 score and accuracy\n",
    "def print_all_metrics():\n",
    "    for i in range(len(model_list)):\n",
    "        print(f'Model: {model_list[i]}, f1 = {f1_scores[i]} accuracy = {accuracies[i]}')\n",
    "        # print(model_list[i], f1_scores[i], accuracies[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average Precision: 95.78%\n",
      "Macro-average Recall: 60.47%\n",
      "Macro-average F1-score: 60.02%\n",
      "Accuracy: 88.01%\n"
     ]
    }
   ],
   "source": [
    "# Train the Naive Bayes classifier\n",
    "mnb = MultinomialNB()\n",
    "fit_and_predict(mnb, 'MultinomialNaiveBayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average Precision: 95.52%\n",
      "Macro-average Recall: 75.77%\n",
      "Macro-average F1-score: 74.72%\n",
      "Accuracy: 92.31%\n"
     ]
    }
   ],
   "source": [
    "# Train the Support Vector Machine classifier\n",
    "svm = SVC()\n",
    "fit_and_predict(svm, 'SupportVectorMachine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average Precision: 96.36%\n",
      "Macro-average Recall: 80.10%\n",
      "Macro-average F1-score: 79.68%\n",
      "Accuracy: 93.21%\n"
     ]
    }
   ],
   "source": [
    "# Train the Support Vector Machine classifier\n",
    "lr = LogisticRegression()\n",
    "fit_and_predict(lr, 'LogisticRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MultinomialNaiveBayes, f1 = 60.02 accuracy = 88.01\n",
      "Model: SupportVectorMachine, f1 = 74.72 accuracy = 92.31\n",
      "Model: LogisticRegression, f1 = 79.68 accuracy = 93.21\n"
     ]
    }
   ],
   "source": [
    "print_all_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
